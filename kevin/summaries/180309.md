## Best Docs to Date
- [API usage overview](https://github.com/openstax/napkin-notes/blob/master/kevin/160921_biglearnApis/api_usage.md)
- [BL deployment overview](https://github.com/openstax/napkin-notes/blob/master/kevin/BiglearnArchitectureDeployment.pdf)
- [Drew's presentation](https://docs.google.com/presentation/d/1qoPqBLD4XqOsIfcM6aJH7IaDQRsxxuA6QBLy4GIZy7w/edit#slide=id.p)
- [Kevin's SPARFA Guide](https://github.com/openstax/sparfa-sandbox/blob/master/klb_sparfa_guide/sparfa_guide.pdf)
- [Kevin's Autoscaling Notes](https://docs.google.com/document/d/1bmn2xYBURE90fiZrdNG5CN28vEBCPJbKukDTbUqntZ4/edit)
- [Kevin's Biglearn Autoscaling Big Picure](https://docs.google.com/document/d/1JGcHIzmHDaDFlQvznzYgsWHuXBRis9qvtwF6pwaYVfQ/edit)

## Zero-Downtime Deployments

I've finally cracked the code
on AWS Cloudformation updates, signaling, etc.,
and can reliably perform zero-downtime deployments
from the command line.

Yee-haw!

## Zero-Downtime Migrations

I've extended my zero-downtime deployment code
to include a special migration ASG,
and now I can also perform necessary steps
for zero-downtime migrations.

Woo-hoo!

There is still some cleanup to be done
(e.g., how to monitor in-progress migrations).

## The Nitty-Gritty

The code is all
[here](https://github.com/kevinburleigh75/aws_autoscaling/tree/klb_elb_expers).

### Update Commands

All of the update commands have the following form:

```
aws cloudformation update-stack 
  --template-url https://s3.amazonaws.com/kevin-templates/ElbTemplate.json 
  --parameters 
      ParameterKey=EnvName,ParameterValue=blah 
      ParameterKey=KeyName,ParameterValue=kevin_va_kp
      ParameterKey=RepoUrl,ParameterValue=https://github.com/kevinburleigh75/aws_autoscaling.git 
      ParameterKey=BranchNameOrSha,ParameterValue=klb_elb_expers 
      ParameterKey=LcImageId,ParameterValue=$LC_IMAGE_ID 
      ParameterKey=MigrationLcImageId,ParameterValue=$MIGRATION_LC_IMAGE_ID
      ParameterKey=MigrationDesiredCapacity,ParameterValue=$MIGRATION_DESIRED_CAPACITY 
      ParameterKey=Asg1DesiredCapacity,ParameterValue=$DESIRED_CAPACITY 
  --stack-name Stack1
```

For the purposes of this writeup,
we'll only really care about the parameters 
that can be controlled by environment variables.

### The Current Situation

Supoose we currently have image `ami-05679357ab362f128` deployed 
and everything is running hunky dorey:

<img src="https://github.com/openstax/napkin-notes/blob/master/kevin/summaries/zdt_before.png" alt="steep" height="200">

There are currently zero instances
in the migrations ASG,
and one instance in the API ASG
(this magnifies the effects
if the ZDT-deployment doesn't work).

Now we want to deploy image `ami-37884c4d`,
and its associated migrations.

### First Update: Running Migrations

As a general rule,
migrations must be compatible
with the currently-deployed code.
So migrations are run first.

We want to leave the API servers alone (for now)
and add one worker (running the new code)
to the migration ASG:

```
export LC_IMAGE_ID=ami-05679357ab362f128
export DESIRED_CAPACITY=1

export MIGRATION_LC_IMAGE_ID=ami-37884c4d
export MIGRATION_DESIRED_CAPACITY=1
```

For now, 
we can check a migration status file
on the migration ASG worker
to see if the migrations were successful:

<img src="https://github.com/openstax/napkin-notes/blob/master/kevin/summaries/zdt_migration_status.png" alt="steep" height="100">

### Second Update: Updating API Servers

We're done with the migration worker,
and ready to change the code on the API servers:

```
export LC_IMAGE_ID=ami-37884c4d
export DESIRED_CAPACITY=1

export MIGRATION_LC_IMAGE_ID=ami-37884c4d
export MIGRATION_DESIRED_CAPACITY=0
```

We can see that,
for a brief period,
requests are being handled
both both versions of API server code:

<img src="https://github.com/openstax/napkin-notes/blob/master/kevin/summaries/zdt_transition.png" alt="steep" height="200">

Eventually, the old API server
is drained of its connections,
and only the new server remains:

<img src="https://github.com/openstax/napkin-notes/blob/master/kevin/summaries/zdt_after.png" alt="steep" height="200">

We are now back to our starting state,
except with different code being run.

Clients experienced zero downtime during this update.


