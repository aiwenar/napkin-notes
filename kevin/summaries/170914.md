## Best Docs to Date
- [API usage overview](https://github.com/openstax/napkin-notes/blob/master/kevin/160921_biglearnApis/api_usage.md)
- [BL deployment overview](https://github.com/openstax/napkin-notes/blob/master/kevin/BiglearnArchitectureDeployment.pdf)
- [Drew's presentation](https://docs.google.com/presentation/d/1qoPqBLD4XqOsIfcM6aJH7IaDQRsxxuA6QBLy4GIZy7w/edit#slide=id.p)
- [Kevin's SPARFA Guide](https://github.com/openstax/sparfa-sandbox/blob/master/klb_sparfa_guide/sparfa_guide.pdf)

## AWS Aurora Postgres (preview mode)

Things worked basically as advertised.

I was able to have 20 `t2.micro` workers
record 3000-4000 messages/sec
into a single `db.r4.large` instance,
and storage and IOPS were automatically scaled as needed
(I ended up with ~40M records, ~11GB of storage, and 1500 IOPS).

There is a single write instance,
and potentially many readers,
and offloading read-only queries
had a noticeable performance improvement.
Read replicas are kept very up-to-date
with the write master (<30ms of lag).

Failover between the write instance
and a newly-promoted reader
took less than 30 seconds,
which is much faster than other RDS failovers.

Cloning the database
was not part of the preview,
but in theory it should take
about as long as a failover (worst-case)
because of the copy-on-write underlying storage.
This should allow us 
to quickly clone `production` databases
for use in `-staging`.
(It might be possible to simulate this 
using the MySQL version of Aurora.)

One potential downside
of using Aurora Postgres
is that we'd need to use a version of postgres
that is supported.
Currently they support 9.6.2,
which is very recent,
but it's not super clear at this point
how long it will take AWS
to support new versions.
To be fair,
we already have this problem to a lesser extent
for our regular RDS instances...

## Weird matrix storage issue

Amanda found (and fixed)
a strange matric serialization issue.
We should probably look into it in more detail
once things are up and running.

