## Best Docs to Date
- [API usage overview](https://github.com/openstax/napkin-notes/blob/master/kevin/160921_biglearnApis/api_usage.md)
- [BL deployment overview](https://github.com/openstax/napkin-notes/blob/master/kevin/BiglearnArchitectureDeployment.pdf)
- [Drew's presentation](https://docs.google.com/presentation/d/1qoPqBLD4XqOsIfcM6aJH7IaDQRsxxuA6QBLy4GIZy7w/edit#slide=id.p)
- [Kevin's SPARFA Guide](https://github.com/openstax/sparfa-sandbox/blob/master/klb_sparfa_guide/sparfa_guide.pdf)
- [Kevin's Autoscaling Notes](https://docs.google.com/document/d/1bmn2xYBURE90fiZrdNG5CN28vEBCPJbKukDTbUqntZ4/edit)
- NEW: [Kevin's Biglearn Autoscaling Big Picure](https://docs.google.com/document/d/1JGcHIzmHDaDFlQvznzYgsWHuXBRis9qvtwF6pwaYVfQ/edit)

## BL API Autoscaling

I started using
[terraform](https://www.terraform.io/)
because it supports modules
that create template infrastructure
but also can be customized via parameters.
This is a huge win over straight AWS templates.

By default, terraform stores the current deployment state
in a local `tfstate` file.
This will absolutely not work for us in general,
so I'm about to start looking into the S3 
[backend](https://www.terraform.io/docs/backends/index.html)
which might address the problems of
(a) multiple developers tweaking infrastructure and
(b) secrets being stored in the `tfstate` file.

It is also becoming apparent 
that we really do want
multiple accounts and/or deployment servers
to handle our different environments.

More things are becoming apparent as well,
but I'll leave them to the next section.

## Scaling in General

_We are completely screwed._

Let's ponder releases for a bit:
* we can't do migrations because they take too long
  * unless we follow a specific set of practices
  * but those practices require rapid back-to-back-to-back releases
  * so we need to support that
  * so we need lots of testing
  * so we need lots of purpose-specific infrastructure
  * so we need lots of automation to build that infrastructure
  * migrations will still take a long time, but at least it won't look like downtime

Speaking of testing...
* we need staging to look like production
  * we can't copy the db because it takes too long
  * we could use Aurora to mitigate this
  * under the hood that's still postgres
  * maybe its performance will scale enough...maybe not

For every problem I solve on this front,
I uncover twenty even worse problems.
And for every solution I suggest,
I hear some excuse why we shouldn't do it.
We lack both the discipline and resolve
(and maybe event the know-how)
to successfully scale our software.

I'm already concerned that the current BL API design,
_if we ever manage to build it_,
won't meet the new scaling goals
as described in the last all-hands meeting.
(It was originally a giant compromise 
meant to be a stopgap
until we could do "real" scaling...)
Do I *know* it won't work? No.
But I don't *know* that it will,
and in the scaling game that means it won't.

I'm pretty much inclined at this point
to ignore anything that we haven't actually demonstrated successfully at scale.
Release processes.
Migrations.
Testing.
All of it.
It's the only way we'll actually get where we need to go.

Don't be surprised
when we end up discarding everything we've done.
Because that is going to happen,
whether or not anyone listens to me.
