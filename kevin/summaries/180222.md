## Best Docs to Date
- [API usage overview](https://github.com/openstax/napkin-notes/blob/master/kevin/160921_biglearnApis/api_usage.md)
- [BL deployment overview](https://github.com/openstax/napkin-notes/blob/master/kevin/BiglearnArchitectureDeployment.pdf)
- [Drew's presentation](https://docs.google.com/presentation/d/1qoPqBLD4XqOsIfcM6aJH7IaDQRsxxuA6QBLy4GIZy7w/edit#slide=id.p)
- [Kevin's SPARFA Guide](https://github.com/openstax/sparfa-sandbox/blob/master/klb_sparfa_guide/sparfa_guide.pdf)
- [Kevin's Autoscaling Notes](https://docs.google.com/document/d/1bmn2xYBURE90fiZrdNG5CN28vEBCPJbKukDTbUqntZ4/edit)
- [Kevin's Biglearn Autoscaling Big Picure](https://docs.google.com/document/d/1JGcHIzmHDaDFlQvznzYgsWHuXBRis9qvtwF6pwaYVfQ/edit)

## BL API Autoscaling

I'm changing my tack on this.
Mainly because there are inevitable problems on the horizon 
that need to be solved 
before the API server can be built and delivered effectively.

There are two main things we need to deal with:
* single API server
  * code, test, deliver, deploy
  * zero downtime
    * need to measure "upness"
  * work kinks out of processes and create tooling for feature:
    * development
    * integration
    * QA
    * delivery
    * deployment
    * release
  * some goals:
    * if automated tests pass, it's deployable
    * non-dev humans only need to do exploratory testing
      * if issue is found, work with dev to create automated test
* multiple API servers
  * server-to-server contract testing
  * end-to-end integration
  * "synchronized" deliveries/deployments
  * setup for testing scenarios
